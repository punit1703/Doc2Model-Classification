# ğŸ§  Multiclass Classification from Scratch (NumPy Implementation)

This project demonstrates a **from-scratch implementation of multiclass classification** using **softmax regression** (a generalization of logistic regression), built entirely with **NumPy** â€” no use of high-level ML libraries like `scikit-learn` for the model.

It is trained and tested on the **Iris dataset**, which includes three classes: `0`, `1`, and `2`.

---

## ğŸ¯ Project Goals

- Implement **softmax regression** for multiclass classification using only NumPy
- Apply the model to real-world data (Iris dataset from `sklearn`)
- Understand how forward pass, softmax activation, cross-entropy loss, and gradients work
- Learn the fundamentals of how libraries like `scikit-learn` and `TensorFlow` build classifiers

---

## ğŸš€ Features

âœ… Implements softmax regression for 3+ classes  
âœ… Supports vectorized forward and backward passes  
âœ… Feature scaling built-in  
âœ… One-hot encoding for targets  
âœ… Uses gradient descent to train the model  
âœ… Includes evaluation (Accuracy)  
âœ… Visualizes predicted outputs using seaborn/matplotlib  
âœ… Can be extended to any multiclass dataset  

---

## ğŸ“š Dataset

- **Dataset:** Iris dataset (`sklearn.datasets.load_iris`)
- **Classes:** 3 (Setosa, Versicolor, Virginica)
- **Features:** 4 numerical features per sample

---

## Folder Structure
<!-- TREEVIEW START -->
    â”œâ”€â”€ implementing_classification/
    â”‚   â”œâ”€â”€ classification/ # Model package
    â”‚   â”‚   â”œâ”€â”€ init.py
    â”‚   â”‚   â””â”€â”€ model.py # Classification logic 
    â”‚   â”œâ”€â”€ classification_model_train.py # Script to load data, train, predict, visualize
    â”‚   â”œâ”€â”€ README.md
    â”‚   â”œâ”€â”€ .gitignore
    â”‚   â””â”€â”€ requirements.txt # NumPy, scikit-learn, matplotlib, seaborn
<!-- TREEVIEW END -->

---
## ğŸ› ï¸ Installation

```bash
git clone https://github.com/punit1703/Doc2Model-Classification
cd Doc2Model-Classification
pip install -r requirements.txt